{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "from tqdm import trange\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectFromModel, SequentialFeatureSelector, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "\n",
    "n_cpu = os.cpu_count()\n",
    "seed = 24\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('./Data/train.csv')\n",
    "print(train_raw.info())\n",
    "test_raw = pd.read_csv('./Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = []\n",
    "for col in train_raw.columns:\n",
    "    if train_raw[col].value_counts().shape[0] == 1:\n",
    "        col_drop.append(col)\n",
    "\n",
    "print(col_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_raw.drop(['class', 'num_outbound_cmds'], axis=1).select_dtypes(include='number')\n",
    "train_Y = train_raw['class'].map({'normal': 1, 'anomaly': 0})\n",
    "test_X = test_raw.drop(['class', 'num_outbound_cmds'], axis=1).select_dtypes(include='number')\n",
    "test_Y = test_raw['class'].map({'normal': 1, 'anomaly': 0})\n",
    "test_X = (test_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "test_X = test_X.clip(0, 1)\n",
    "train_X = (train_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_X.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = train_X.corr()\n",
    "model = RandomForestClassifier(n_estimators=200, n_jobs=n_cpu-1, random_state=seed)\n",
    "selected_features = []\n",
    "\n",
    "original_features = train_X.columns.tolist()\n",
    "print(original_features)\n",
    "start_time = time.time()\n",
    "while len(original_features) > 0:\n",
    "    indices = correlation_matrix[correlation_matrix.loc[:, original_features[0]] >= 0.8].index.tolist()\n",
    "    print(indices)\n",
    "    if len(indices) == 1:\n",
    "        selected_features.append(indices[0])\n",
    "        original_features.remove(indices[0])\n",
    "        continue\n",
    "\n",
    "    selector = SelectFromModel(model, threshold=-np.inf, max_features=1)\n",
    "    selector.fit(train_X[indices], train_Y)\n",
    "    selected_features.append([b for a, b in zip(selector.get_support(), indices) if a][0])\n",
    "    original_features = [col for col in original_features if col not in indices]\n",
    "\n",
    "print(f'time cost: {time.time()-start_time}')\n",
    "print(f'selected features: {selected_features}')\n",
    "\n",
    "train_X = train_X[selected_features]\n",
    "test_X = test_X[selected_features]\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, n_jobs=n_cpu-1, random_state=seed)\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k='all')\n",
    "selector.fit(train_X, train_Y)\n",
    "sorted_index = np.argsort(selector.scores_)\n",
    "mi_features = train_X.columns[sorted_index].tolist()\n",
    "print(mi_features)\n",
    "\n",
    "del selector\n",
    "\n",
    "kf = StratifiedKFold(shuffle=True, random_state=seed)\n",
    "\n",
    "selector = SequentialFeatureSelector(model, n_features_to_select=1, scoring='f1', cv=kf, n_jobs=n_cpu-1)\n",
    "sfs_features = []\n",
    "for i in trange(train_X.shape[1]-1):\n",
    "    train_X2 = train_X.drop(sfs_features, axis=1)\n",
    "    selector.fit(train_X2, train_Y)\n",
    "    f = train_X2.columns[selector.get_support()][0]\n",
    "    sfs_features.append(f)\n",
    "\n",
    "sfs_features.append(train_X.columns.drop(sfs_features)[0])\n",
    "print(sfs_features)\n",
    "\n",
    "del selector\n",
    "\n",
    "selector = RFE(model, n_features_to_select=1)\n",
    "selector.fit(train_X, train_Y)\n",
    "sorted_index = np.argsort(selector.ranking_)\n",
    "rfe_features = train_X.columns[sorted_index].tolist()\n",
    "print(rfe_features)\n",
    "\n",
    "del selector\n",
    "\n",
    "selector = RFE(model, n_features_to_select=1)\n",
    "selector.fit(train_X, train_Y)\n",
    "sorted_index = np.argsort(selector.estimator_.feature_importances_)\n",
    "imp_features = train_X.columns[sorted_index].tolist()\n",
    "print(imp_features)\n",
    "\n",
    "del selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, model_name):\n",
    "    score_all = pd.DataFrame()\n",
    "    plt.subplots(2, 2)\n",
    "    for k, (feature_set, name) in enumerate(zip([mi_features, sfs_features, rfe_features, imp_features], ['Univariate', 'SFS', 'RFE', 'Importance'])):\n",
    "        cv_score = []\n",
    "        test_score = []\n",
    "        for i in trange(train_X.shape[1]):\n",
    "            train_X2 = train_X[feature_set[:i+1]].copy()\n",
    "            cv = cross_val_score(model, train_X2, train_Y, scoring='f1', cv=kf)\n",
    "            cv_score.append(cv.mean())\n",
    "\n",
    "            model.fit(train_X2, train_Y)\n",
    "            predict = model.predict(test_X[feature_set[:i+1]])\n",
    "            test_score.append(f1_score(test_Y, predict))\n",
    "        score_all[f'cv_score_{name}_{model_name}'] = cv_score\n",
    "        score_all[f'test_score_{name}_{model_name}'] = test_score\n",
    "\n",
    "        plt.subplot(2, 2, k)\n",
    "        plt.title(name)\n",
    "        plt.plot(range(train_X.shape[1]), cv_score, color='blue', linestyle='-', label='CV Score')\n",
    "        plt.plot(range(train_X.shape[1]), test_score, color='red', linestyle='-', label='Test Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return score_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=100, solver='liblinear', random_state=seed, n_jobs=n_cpu-1)\n",
    "score_all_LR = get_scores(model, 'LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=200, random_state=seed)\n",
    "score_all_GB = get_scores(model, 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(50, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.binary_crossentropy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed)\n",
    "\n",
    "kf = StratifiedKFold(shuffle=True, random_state=seed)\n",
    "\n",
    "score_all_NN = pd.DataFrame()\n",
    "plt.subplots(2, 2)\n",
    "for k, (feature_set, name) in enumerate(zip([mi_features, sfs_features, rfe_features, imp_features], ['Univariate', 'SFS', 'RFE', 'Importance'])):\n",
    "    cv_score = []\n",
    "    test_score = []\n",
    "    for k in trange(train_X.shape[1]):\n",
    "        model = create_model(k+1)\n",
    "\n",
    "        cv = []\n",
    "        train_X2 = train_X[feature_set[:k+1]].copy()\n",
    "        for train_index, test_index in kf.split(train_X2, train_Y):\n",
    "            x_train_fold, x_test_fold = train_X2.iloc[train_index, :], train_X2.iloc[test_index, :]\n",
    "            y_train_fold, y_test_fold = train_Y.iloc[train_index], train_Y.iloc[test_index]\n",
    "\n",
    "            model.fit(x_train_fold.values, y_train_fold.values,\n",
    "                    epochs=15, batch_size=100,\n",
    "                    use_multiprocessing=True, verbose=0)\n",
    "            \n",
    "            predict = model.predict(test_X[feature_set[:k+1]], use_multiprocessing=True)\n",
    "            predict = np.where(predict < 0.5, 0, 1)\n",
    "            cv.append(f1_score(test_Y, predict))\n",
    "        cv_score.append(np.mean(cv_score))\n",
    "\n",
    "        model.fit(train_X2.values, train_Y.values,\n",
    "                epochs=15, batch_size=100,\n",
    "                use_multiprocessing=True, verbose=0)\n",
    "        predict = model.predict(test_X[feature_set[:k+1]], use_multiprocessing=True)\n",
    "        predict = np.where(predict < 0.5, 0, 1)\n",
    "        test_score.append(f1_score(test_Y, predict))\n",
    "\n",
    "        del model\n",
    "\n",
    "    score_all_NN[f'cv_score_{name}_NN'] = cv_score\n",
    "    score_all_NN[f'test_score_{name}_NN'] = test_score\n",
    "\n",
    "    plt.subplot(2, 2, k)\n",
    "    plt.title(name)\n",
    "    plt.plot(range(train_X.shape[1]), cv_score, color='blue', linestyle='-', label='CV Score')\n",
    "    plt.plot(range(train_X.shape[1]), test_score, color='red', linestyle='-', label='Test Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([score_all_LR, score_all_GB, score_all_NN], axis=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
